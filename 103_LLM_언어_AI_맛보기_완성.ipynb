{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joyschool/ktcloud_genai/blob/main/103_LLM_%EC%96%B8%EC%96%B4_AI_%EB%A7%9B%EB%B3%B4%EA%B8%B0_%EC%99%84%EC%84%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ì–¸ì–´ AI ì´í•´**"
      ],
      "metadata": {
        "id": "xAPO58qbDYi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NAmo5uhXQ46c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ğŸ’¡ **NOTE**\n",
        "    - ì´ ë…¸íŠ¸ë¶ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì½”ë©ì—ì„œëŠ” **ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > í•˜ë“œì›¨ì–´ ê°€ì†ê¸° > T4 GPU**ë¥¼ ì„ íƒí•˜ì„¸ìš”.\n",
        "    - **T4 GPU : 16GB VRAM**\n",
        "\n",
        "- ğŸ’¡**ì½”ë“œ ë‚´ìš©**\n",
        "    - ì–¸ì–´ AIì˜ ì´í•´ë¥¼ ë•ëŠ” ì½”ë“œ\n",
        "    - 2000ë…„ëŒ€ ì´ì „ì˜ ìì—°ì–´ ì²˜ë¦¬(NLP) ê³¼ì • ì´í•´ë¥¼ ë•ëŠ” ì˜ˆì œë¡œ êµ¬ì„±í•¨\n",
        "    - ì–´ë–¤ ëª¨ë¸ì€ ì‹¤í–‰ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ.(ì½”ë©ì—ì„œëŠ” RAMì„ ëª¨ë‘ ì‚¬ìš© í›„ ì„¸ì…˜ì´ ë‹¤ìš´ ë  ìˆ˜ ìˆìŒ)\n"
      ],
      "metadata": {
        "id": "KHIcfXn8RArA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "K-OX9xcYMp_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[Quicktour] transformersë¡œ í™•ì¸í•˜ëŠ” ì–¸ì–´ AIì˜ ê¸°ëŠ¥ ì˜ˆ**"
      ],
      "metadata": {
        "id": "1TCZmmIJs4D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Hugging Face**\n",
        "    - Hugging FaceëŠ” AI ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì„ ê³µìœ Â·í™œìš©í•  ìˆ˜ ìˆëŠ” ëŒ€í‘œì ì¸ ì˜¤í”ˆì†ŒìŠ¤ í”Œë«í¼, ì»¤ë®¤ë‹ˆí‹°\n",
        "        - **ëª¨ë¸ í—ˆë¸Œ(Model Hub)** : ìˆ˜ë§Œ ê°œì˜ ê³µê°œëœ ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ëˆ„êµ¬ë‚˜ ë‹¤ìš´ë¡œë“œÂ·í™œìš© ê°€ëŠ¥\n",
        "        - **ë°ì´í„°ì…‹ í—ˆë¸Œ(Datasets)** : ë‹¤ì–‘í•œ í‘œì¤€/ë¹„í‘œì¤€ ë°ì´í„°ì…‹ì„ ê°„í¸í•˜ê²Œ ë¶ˆëŸ¬ì™€ ì‹¤í—˜ ê°€ëŠ¥\n",
        "        - **Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬** : BERT, GPT, T5, LLaMA ë“± ìµœì‹  NLPÂ·ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ ì†ì‰½ê²Œ ì‚¬ìš© ê°€ëŠ¥\n",
        "        - **PEFT/Accelerate ë“± ë„êµ¬** : íŒŒì¸íŠœë‹Â·ë¶„ì‚° í•™ìŠµÂ·ìµœì í™” ì§€ì›\n",
        "        - **ì»¤ë®¤ë‹ˆí‹°**: ì—°êµ¬ìÂ·ê°œë°œìê°€ ëª¨ë¸ê³¼ ì½”ë“œë¥¼ ê³µìœ í•˜ê³  í˜‘ì—…í•  ìˆ˜ ìˆëŠ” ìƒíƒœê³„\n",
        "\n",
        "- **transformers**\n",
        "    - transformers library https://huggingface.co/docs/transformers/index\n",
        "    - Hugging Faceì—ì„œ ì œê³µí•˜ëŠ” ì‚¬ì „ í›ˆë ¨ëœ AI ëª¨ë¸ë“¤ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "    - ë³µì¡í•œ AI ëª¨ë¸ì„ ê°„ë‹¨í•œ ì½”ë“œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë„êµ¬\n",
        "\n",
        "- **pipeline**\n",
        "    - https://huggingface.co/docs/transformers/main/en/main_classes/pipelines\n",
        "    - pipelineì€ ìì—°ì–´ ì²˜ë¦¬(NLP)Â·ë¹„ì „Â·ì˜¤ë””ì˜¤ ë“± ë‹¤ì–‘í•œ AI íƒœìŠ¤í¬ë¥¼ ì‰½ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ë¯¸ë¦¬ êµ¬ì„±ëœ ì¶”ë¡ (ì‹¤í–‰) ë„êµ¬\n",
        "    - íƒœìŠ¤í¬ ì´ë¦„(ì˜ˆ: \"sentiment-analysis\", \"translation\")ì„ ì…ë ¥í•˜ë©´,ìë™ìœ¼ë¡œ ì í•©í•œ ëª¨ë¸ + í† í¬ë‚˜ì´ì € + ì „/í›„ì²˜ë¦¬ ë¡œì§ì„ ë¶ˆëŸ¬ì™€,ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸/ì´ë¯¸ì§€/ì˜¤ë””ì˜¤ë¥¼ ë°”ë¡œ ë„£ì–´ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆê²Œ í•¨\n",
        "\n",
        "    - **pipeline(sentiment-analysis)**\n",
        "        - Hugging Face Pipelines Documentation :  \n",
        "        - í…ìŠ¤íŠ¸ì˜ ê°ì •(ê¸ì •/ë¶€ì •) ë¶„ì„ì— íŠ¹í™”ëœ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì˜ ì‘ì—…(task) ì´ë¦„\n",
        "        - ê°ì • ë¶„ì„ì— íŠ¹í™”ëœ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì‘ì—…(task) ì´ë¦„\n",
        "        - (AIëª¨ë¸ X) ë‚´ë¶€ì ìœ¼ë¡œ BERT, RoBERTa, DistilBERT ë“±ì˜ ì‹¤ì œ ì‹ ê²½ë§ ëª¨ë¸ì´ ë™ì‘"
      ],
      "metadata": {
        "id": "hSl3zLaYboW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ì˜ˆì œ: ë‚˜ë§Œì˜ ì˜í™” í‰ë¡  ë¶„ì„ê¸° (ìì—°ì–´ ì´í•´ - NLU)**\n",
        "- **ëª©í‘œ**: ì˜í™” ë¦¬ë·°ë¥¼ ì…ë ¥í•˜ë©´, í•´ë‹¹ ë¦¬ë·°ê°€ ê¸ì •ì ì¸ì§€ ë¶€ì •ì ì¸ì§€ë¥¼ ë§ì¶”ê³ , ë¦¬ë·°ì— ì–¸ê¸‰ëœ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë½‘ì•„ë‚´ëŠ” í”„ë¡œê·¸ë¨\n",
        "- **í•µì‹¬ ê¸°ìˆ **: ê°ì„± ë¶„ì„(Sentiment Analysis)"
      ],
      "metadata": {
        "id": "NLclNnCla-rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show transformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "F-abktY87pVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Faceì˜ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©\n",
        "from transformers import pipeline\n",
        "\n",
        "# ê°ì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸ ë¡œë“œ (sentiment-analysisëŠ” \"ì‘ì—… ìœ í˜•\"ì„ ì§€ì •í•˜ëŠ” ê²ƒ)\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")  # Task : sentiment-analysis\n",
        "\n",
        "review = \"ì´ ì˜í™”ëŠ” ì •ë§ ì‹œê°„ ê°€ëŠ” ì¤„ ëª¨ë¥´ê³  ë´¤ì–´ìš”. ë°°ìš°ë“¤ ì—°ê¸°ê°€ ìµœê³ !\"\n",
        "\n",
        "result = sentiment_analyzer(review)\n",
        "\n",
        "print('\\nâœ… ê°ì„± ë¶„ì„(Sentiment Analysis) ê²°ê³¼')\n",
        "print(f\"ë¦¬ë·°: {review}\")\n",
        "print(f\"ë¶„ì„ ê²°ê³¼: {result}\") # [{'label': 'POSITIVE', 'score': 0.99...}]\n",
        "\n",
        "# í•µì‹¬ êµ¬ë¬¸ ì¶”ì¶œì€ ë³„ë„ì˜ ëª¨ë¸ì´ë‚˜ ê¸°ë²•ì´ í•„ìš”\n",
        "# ì˜ˆì‹œ: \"ë°°ìš°ë“¤ ì—°ê¸°\", \"ì‹œê°„ ê°€ëŠ” ì¤„\" ë“±ì„ ì¶”ì¶œ"
      ],
      "metadata": {
        "id": "nXxu78mQa-0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"ì´ ì˜í™”ë¥¼ ë³´ëŠ” ë‚´ë‚´ í˜ë“¤ì—ˆì–´. ë„ˆë¬´ ì§€ë£¨í–ˆì–´.\"\n",
        "\n",
        "result = sentiment_analyzer(review)\n",
        "\n",
        "print('\\nâœ… ê°ì„± ë¶„ì„(Sentiment Analysis) ê²°ê³¼')\n",
        "print(f\"ë¦¬ë·°: {review}\")\n",
        "print(f\"ë¶„ì„ ê²°ê³¼: {result}\") # [{'label': 'POSITIVE', 'score': 0.99...}]"
      ],
      "metadata": {
        "id": "jEAmPzZX9xSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(AIëª¨ë¸ êµ¬ì„±íŒŒì¼) ë‹¤ìš´ë¡œë“œ ì§„í–‰ë°” On/Off**"
      ],
      "metadata": {
        "id": "0JCRrWclPL0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "# 1. ì›ë˜ initì„ ë°±ì—…\n",
        "tqdm_init_backup = tqdm.tqdm.__init__\n",
        "\n",
        "# # 2. ì§„í–‰ë°” ë„ê¸°\n",
        "# tqdm.tqdm.__init__ = lambda *args, **kwargs: None\n",
        "\n",
        "# 3. ë‹¤ì‹œ ì¼œê¸° (ë³µì›)\n",
        "tqdm.tqdm.__init__ = tqdm_init_backup\n"
      ],
      "metadata": {
        "id": "Qqyjc1kL_iHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **(AIëª¨ë¸ êµ¬ì„±íŒŒì¼) íŒŒì¼ êµ¬ì„± ì˜ˆ:(Taskë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆë‹¤)**\n",
        "|íŒŒì¼ ì´ë¦„\t|ë¹„ìœ |\tí•µì‹¬ ì—­í• |\n",
        "|---|---|---|\n",
        "|model.safetensors\t|ğŸ§  AIì˜ ë‡Œ (ì—”ì§„)|\tëª¨ë¸ì˜ í•™ìŠµëœ ê°€ì¤‘ì¹˜(weights), ì¦‰ ì‹¤ì§ˆì ì¸ ì§€ëŠ¥ì´ ë‹´ê¸´ ê°€ì¥ í•µì‹¬ì ì¸ íŒŒì¼ì…ë‹ˆë‹¤.|\n",
        "|config.json|\tğŸ“œ AIì˜ ì„¤ê³„ë„|\tëª¨ë¸ì˜ êµ¬ì¡°(ëª‡ ê°œì˜ ì¸µ, ì–´ë–¤ ì¢…ë¥˜ì˜ ëª¨ë¸ ë“±)ê°€ ì •ì˜ëœ ì„¤ì • íŒŒì¼ì…ë‹ˆë‹¤.|\n",
        "|vocab.txt\t|ğŸ“– AIì˜ ë‹¨ì–´ ì‚¬ì „|\tëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ë‹¨ì–´(í† í°)ì™€ ê·¸ì— í•´ë‹¹í•˜ëŠ” ê³ ìœ  ë²ˆí˜¸ ëª©ë¡ì…ë‹ˆë‹¤.|\n",
        "|tokenizer_config.json\t|ğŸ“ ì‚¬ì „ ì‚¬ìš© ì„¤ëª…ì„œ\t|ë‹¨ì–´ ì‚¬ì „ì„ ì–´ë–¤ ê·œì¹™(ì†Œë¬¸ìí™” ì—¬ë¶€, íŠ¹ìˆ˜ í† í° ë“±)ìœ¼ë¡œ ì‚¬ìš©í• ì§€ ì •ì˜í•œ íŒŒì¼ì…ë‹ˆë‹¤.|\n"
      ],
      "metadata": {
        "id": "N3xf0z5da-_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **(AIëª¨ë¸ êµ¬ì„±íŒŒì¼) ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ìœ„ì¹˜(ìºì‹œíŒŒì¼) : ì½”ë©**\n",
        "    - /root/.cache/huggingface/hub ~ /snapshots/...\n"
      ],
      "metadata": {
        "id": "QuGMeNFNgqZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ìºì‹œ í´ë”ì— ì–´ë–¤ ëª¨ë¸ë“¤ì´ ì €ì¥ë˜ì–´ ìˆëŠ”ì§€ ëª©ë¡ì„ ë´…ë‹ˆë‹¤.\n",
        "!ls /root/.cache/huggingface/hub/"
      ],
      "metadata": {
        "id": "QVputcVhgrFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ëª¨ë¸ ì§ì ‘ ì§€ì •í•˜ê¸°**"
      ],
      "metadata": {
        "id": "LNcbyi4arCWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# ê°ì • ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”\n",
        "#   model=<ì—…ë¡œë”ì´ë¦„>/<ëª¨ë¸ì´ë¦„>\n",
        "#       nlptown â†’ ëª¨ë¸ì„ ê³µê°œí•œ Hugging Face ì‚¬ìš©ì(í˜¹ì€ ì¡°ì§) ê³„ì •ëª…\n",
        "#       bert-base-multilingual-uncased-sentiment â†’ ëª¨ë¸ì˜ ì´ë¦„\n",
        "#           BERT ê¸°ë°˜\n",
        "#           ë‹¤êµ­ì–´ ì§€ì›\n",
        "#           ëŒ€ì†Œë¬¸ì êµ¬ë¶„í•˜ì§€ ì•ŠìŒ (uncased)\n",
        "#           ê°ì„± ë¶„ì„ìš©ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\",\n",
        "                             model=\"nlptown/bert-base-multilingual-uncased-sentiment\" )\n",
        "\n",
        "\n",
        "# ìƒ˜í”Œ ë¦¬ë·° ë°ì´í„°\n",
        "reviews = [\n",
        "    \"ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”! ì¶”ì²œí•©ë‹ˆë‹¤.\",\n",
        "    \"ë°°ì†¡ì´ ë„ˆë¬´ ëŠ¦ì—ˆì–´ìš”. ì‹¤ë§ìŠ¤ëŸ½ë„¤ìš”.\",\n",
        "    \"ê°€ê²© ëŒ€ë¹„ ê´œì°®ì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤.\"\n",
        "]\n",
        "\n",
        "# ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
        "results = []\n",
        "for review in reviews:\n",
        "    result = sentiment_analyzer(review)\n",
        "    results.append({\n",
        "        'text': review,\n",
        "        'sentiment': result[0]['label'],\n",
        "        'confidence': result[0]['score']\n",
        "    })\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "print('\\nâœ… ê°ì„± ë¶„ì„(Sentiment Analysis) ê²°ê³¼')\n",
        "df"
      ],
      "metadata": {
        "id": "3RBxHyjAq9Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Taskë³„ ê¸°ë³¸ëª¨ë¸ ì°¸ê³ ** : ë²„ì „ë³„ë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ\n",
        "\n",
        "|íƒœìŠ¤í¬ ì´ë¦„|ê¸°ë³¸ ëª¨ë¸ ì˜ˆì‹œ (ì§€ì •í•˜ì§€ ì•Šì„ ë•Œ)|\n",
        "|---|---|\n",
        "|text-generation | gpt2 |\n",
        "|text-classification / sentiment-analysis| distilbert-base-uncased-finetuned-sst-2-english |\n",
        "|fill-mask|bert-base-uncased|\n",
        "|ner / token-classification|dslim/bert-base-NER ë˜ëŠ” BERT ê¸°ë°˜ NER ëª¨ë¸|\n",
        "|question-answering | distilbert-base-uncased-distilled-squad ë˜ëŠ” BERT ê¸°ë°˜ QA ëª¨ë¸|\n",
        "|summarization | facebook/bart-large-cnn |\n",
        "|translation (ì˜ˆ: translation_en_to_fr) | Helsinki-NLP/opus-mt-en-fr |\n",
        "|zero-shot-classification  |facebook/bart-large-mnli |\n",
        "|conversational | microsoft/DialoGPT-small ë˜ëŠ” Chat ëª¨ë¸ |\n",
        "\n"
      ],
      "metadata": {
        "id": "IDcR5MBOaN_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ì˜ˆì œ: ë¬¸ì¥ ì†Œì„¤ ì´ì–´ ì“°ê¸° (ìì—°ì–´ ìƒì„± - NLG)**\n",
        "- **ëª©í‘œ**: ì¬ë¯¸ìˆëŠ” ì†Œì„¤ì˜ ì²« ë¬¸ì¥ì„ ì œì‹œí•˜ë©´, AIê°€ ê·¸ëŸ´ë“¯í•œ ë‹¤ìŒ ë¬¸ì¥ë“¤ì„ ìë™ìœ¼ë¡œ ìƒì„±í•´ í•˜ë‚˜ì˜ ì§§ì€ ì´ì•¼ê¸°ë¥¼ ì™„ì„±í•˜ëŠ” í”„ë¡œê·¸ë¨\n",
        "- **í•µì‹¬ ê¸°ìˆ **: í…ìŠ¤íŠ¸ ìƒì„±(Text Generation)"
      ],
      "metadata": {
        "id": "EXPJs5hxa_M3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Faceì˜ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©\n",
        "from transformers import pipeline\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸ ë¡œë“œ (ì˜ˆ: GPT-2)\n",
        "text_generator = pipeline(\"text-generation\")\n",
        "\n",
        "prompt = \"ì–´ëŠ ë‚  ì•„ì¹¨, ì ì—ì„œ ê¹¨ì–´ë³´ë‹ˆ ë‚´ ë°©ì— ì½”ë¼ë¦¬ê°€ ìˆì—ˆë‹¤.\"\n",
        "\n",
        "story = text_generator(prompt,\n",
        "                       max_length=100,\n",
        "                       num_return_sequences=3)\n",
        "\n",
        "print('\\nâœ… í…ìŠ¤íŠ¸ ìƒì„±(Text Generation) ê²°ê³¼')\n",
        "print(\"--- AIê°€ ì™„ì„±í•œ ì´ì•¼ê¸° ---\")\n",
        "print(story[0]['generated_text'])\n",
        "story"
      ],
      "metadata": {
        "id": "BITqxWoda_Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(story)"
      ],
      "metadata": {
        "id": "eEmWFPsdFTkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ì˜ˆì œ 3: í…ìŠ¤íŠ¸ ìš”ì•½ (Text Summarization)**\n",
        "- **ëª©í‘œ**: ê¸´ ê¸€(ë‰´ìŠ¤ ê¸°ì‚¬, ë…¼ë¬¸, ë³´ê³ ì„œ ë“±)ì„ AIë¥¼ ì´ìš©í•´ í•µì‹¬ ë‚´ìš©ë§Œ ë‹´ì€ ì§§ì€ ê¸€ë¡œ ìë™ ìš”ì•½í•˜ëŠ” í”„ë¡œê·¸ë¨\n",
        "- **í•µì‹¬ ê¸°ìˆ **: í…ìŠ¤íŠ¸ ìš”ì•½ (Text Summarization)"
      ],
      "metadata": {
        "id": "z4z-C4ZcrXY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# ìš”ì•½ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”\n",
        "summarizer = pipeline(\"summarization\",\n",
        "                     model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# ê¸´ í…ìŠ¤íŠ¸ ì˜ˆì‹œ\n",
        "long_text = \"\"\"\n",
        "ì¸ê³µì§€ëŠ¥(AI)ì€ 21ì„¸ê¸° ê°€ì¥ ì¤‘ìš”í•œ ê¸°ìˆ  ì¤‘ í•˜ë‚˜ë¡œ ì—¬ê²¨ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "íŠ¹íˆ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œëŠ” BERT, GPTì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ë“±ì¥ìœ¼ë¡œ\n",
        "ì¸í•´ ê¸°ê³„ê°€ ì¸ê°„ ìˆ˜ì¤€ì˜ ì–¸ì–´ ì´í•´ì™€ ìƒì„± ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "ì´ëŸ¬í•œ ë°œì „ì€ êµìœ¡, ì˜ë£Œ, ê¸ˆìœµ, ì—”í„°í…Œì¸ë¨¼íŠ¸ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ\n",
        "í˜ì‹ ì ì¸ ë³€í™”ë¥¼ ê°€ì ¸ì˜¤ê³  ìˆìœ¼ë©°, ì•ìœ¼ë¡œë„ ê³„ì†í•´ì„œ ë°œì „í•  ê²ƒìœ¼ë¡œ\n",
        "ì˜ˆìƒë©ë‹ˆë‹¤. í•˜ì§€ë§Œ ë™ì‹œì— ìœ¤ë¦¬ì  ë¬¸ì œ, ì¼ìë¦¬ ëŒ€ì²´, í¸í–¥ì„± ë“±ì˜\n",
        "ë¬¸ì œë„ ì œê¸°ë˜ê³  ìˆì–´ ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "\"\"\"\n",
        "\n",
        "# ìš”ì•½ ìˆ˜í–‰\n",
        "summary = summarizer(long_text,\n",
        "                    max_length=50,\n",
        "                    min_length=10,\n",
        "                    do_sample=False)\n",
        "\n",
        "print('\\nâœ… í…ìŠ¤íŠ¸ ìš”ì•½ (Text Summarization) ê²°ê³¼')\n",
        "print(\"ì›ë¬¸ ê¸¸ì´:\", len(long_text.split()))\n",
        "print(\"ìš”ì•½ë¬¸:\", summary[0]['summary_text'])\n",
        "print(\"ìš”ì•½ë¬¸ ê¸¸ì´:\", len(summary[0]['summary_text'].split()))"
      ],
      "metadata": {
        "id": "dQRCtJEzrXf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ì˜ˆì œ 4: ì œë¡œìƒ· í…ìŠ¤íŠ¸ ë¶„ë¥˜ (ZeroShotClassification)**\n",
        "- **ì œë¡œìƒ· í…ìŠ¤íŠ¸ ë¶„ë¥˜ (ZeroShotClassification)**\n",
        "    - ì •ì˜: í•™ìŠµ ë°ì´í„°ì— ì—†ëŠ” ìƒˆë¡œìš´ ë¼ë²¨(ì¹´í…Œê³ ë¦¬)ì— ëŒ€í•´ì„œë„, ì‚¬ì „í•™ìŠµëœ ì–¸ì–´ëª¨ë¸ì„ í™œìš©í•´ ë¬¸ì¥ì„ í•´ë‹¹ ë¼ë²¨ë¡œ ë¶„ë¥˜í•˜ëŠ” ë°©ë²•\n",
        "    - ì›ë¦¬: ë¼ë²¨ì„ â€œì„¤ëª… ë¬¸ì¥(hypothesis)â€ìœ¼ë¡œ ë°”ê¿”ì„œ, ìì—°ì–´ ì¶”ë¡ (NLI, Natural Language Inference) ë¬¸ì œë¡œ ë³€í™˜ í›„ ëª¨ë¸ì´ ì°¸/ê±°ì§“ì„ íŒë‹¨í•˜ë„ë¡ í•¨.\n",
        "    - ì˜ˆ:\n",
        "        - ë¬¸ì¥: \"ì´ ì˜í™”ëŠ” ì •ë§ ì¬ë°Œì—ˆë‹¤\"\n",
        "        - ë¼ë²¨ í›„ë³´: [\"ê¸ì •\", \"ë¶€ì •\"]\n",
        "        - ë³€í™˜ â†’ \"ì´ ë¬¸ì¥ì€ ê¸ì •ì„ í‘œí˜„í•œë‹¤.\" (ì°¸/ê±°ì§“ ì˜ˆì¸¡)\n",
        "    -\n",
        "- **ëª©í‘œ**: ê° ë‹¨ì–´ì™€ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¤ìŠ¤ë¡œ ì¶”ë¡ í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ë¶„ë¥˜í•˜ëŠ” í”„ë¡œê·¸ë¨\n",
        "- **í•µì‹¬ ê¸°ìˆ **: ì œë¡œìƒ· ë¶„ë¥˜(ZeroShotClassification)--> ìì—°ì–´ ì¶”ë¡  (NLI, Natural Language Inference)\n",
        "    - NLI ëª¨ë¸ì€ ë‘ ë¬¸ì¥(ì „ì œ, ê°€ì„¤)ì„ ë³´ê³  ê·¸ ê´€ê³„ê°€ 'ì°¸(Entailment)', 'ëª¨ìˆœ(Contradiction)', 'ì¤‘ë¦½(Neutral)' ì¤‘ ë¬´ì—‡ì¸ì§€ íŒë‹¨í•˜ë„ë¡ í›ˆë ¨ë¨\n",
        "    - ê° ë‹¨ì–´ì™€ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¤ìŠ¤ë¡œ ì¶”ë¡ í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ë¶„ë¥˜ ì§„í–‰\n",
        "- **ì…ë ¥** :\n",
        "    - ë¶„ë¥˜í•  ë¬¸ì¥\n",
        "    - í›„ë³´ ë¼ë²¨"
      ],
      "metadata": {
        "id": "qFrxAVx8ywRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# ì œë¡œìƒ· ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "\n",
        "# ë¶„ë¥˜í•  ë¬¸ì¥\n",
        "sequence_to_classify = \"ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° CED ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.\"\n",
        "\n",
        "# í›„ë³´ ë¼ë²¨ (ë¯¸ë¦¬ í•™ìŠµì‹œí‚¬ í•„ìš” ì—†ì´, ê·¸ëƒ¥ ì›í•˜ëŠ” ë¼ë²¨ì„ ë‚˜ì—´)\n",
        "candidate_labels = ['ê²½ì œ', 'ì •ì¹˜', 'IT', 'ìŠ¤í¬ì¸ ', 'ì—°ì˜ˆ']\n",
        "\n",
        "# ë¶„ë¥˜ ì‹¤í–‰\n",
        "result = classifier(sequence_to_classify, candidate_labels)\n",
        "\n",
        "# print ë¬¸ì˜ ì„¤ëª…ì„ 'ì œë¡œìƒ· ë¶„ë¥˜'ë¡œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.\n",
        "print('\\nâœ… ì œë¡œìƒ· ë¶„ë¥˜ (Zero-Shot Classification) ê²°ê³¼')\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "HBMhCBJUy5n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 1. XLM-RoBERTa ê¸°ë°˜ ë‹¤êµ­ì–´ ì œë¡œìƒ· ë¶„ë¥˜\n",
        "classifier_xlm = pipeline(\"zero-shot-classification\",\n",
        "                          model=\"joeddav/xlm-roberta-large-xnli\")\n",
        "\n",
        "# 2. mDeBERTa-v3 ê¸°ë°˜ ë‹¤êµ­ì–´ ì œë¡œìƒ· ë¶„ë¥˜\n",
        "classifier_mdeberta = pipeline(\"zero-shot-classification\",\n",
        "                               model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\")\n",
        "\n",
        "# 3. DeBERTa-v3 ê¸°ë°˜ ì˜ì–´ ì „ìš© ì œë¡œìƒ· ë¶„ë¥˜\n",
        "classifier_deberta = pipeline(\"zero-shot-classification\",\n",
        "                              model=\"cross-encoder/nli-deberta-v3-base\")\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë¬¸ì¥\n",
        "sequence = \"ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° CEO ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.\"\n",
        "candidate_labels = [\"ê²½ì œ\", \"ì •ì¹˜\", \"IT\", \"ìŠ¤í¬ì¸ \", \"ì—°ì˜ˆ\"]\n",
        "\n",
        "# ì‹¤í–‰ ì˜ˆì‹œ\n",
        "print(\"âœ… XLM-RoBERTa ê²°ê³¼\")\n",
        "print(classifier_xlm(sequence, candidate_labels))\n",
        "\n",
        "print(\"\\nâœ… mDeBERTa ê²°ê³¼\")\n",
        "print(classifier_mdeberta(sequence, candidate_labels))\n",
        "\n",
        "print(\"\\nâœ… DeBERTa (ì˜ì–´ ìœ„ì£¼) ê²°ê³¼\")\n",
        "print(classifier_deberta(sequence, candidate_labels))\n"
      ],
      "metadata": {
        "id": "dW8TpnnFfT1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **[ì£¼ì˜!]** ëª¨ë¸ì„ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´, ê¸°ë³¸ì ìœ¼ë¡œ ì˜ì–´ ë°ì´í„° ìœ„ì£¼ë¡œ í›ˆë ¨ëœ ëª¨ë¸ì´ ì‚¬ìš©ë¨\n",
        "    - í•´ê²° ë°©ë²•: í•œêµ­ì–´ ëª¨ë¸ + í•œêµ­ì–´ ê°€ì„¤ í…œí”Œë¦¿ ì‚¬ìš©\n",
        "        - (1) í•œêµ­ì–´ ì„±ëŠ¥ì´ ê²€ì¦ëœ ëª¨ë¸ ì‚¬ìš©í•˜ê³ ,\n",
        "        - (2) ê°€ì„¤ í…œí”Œë¦¿ ë˜í•œ í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê²Œ ì§€ì •í•˜ì—¬ ëª¨ë¸ì´ ì˜¨ì „íˆ í•œêµ­ì–´ í™˜ê²½ì—ì„œë§Œ ì¶”ë¡ í•˜ë„ë¡ í•¨\n",
        "    - klue/roberta-large\n",
        "        - KLUE(Korean Language Understanding Evaluation) ë²¤ì¹˜ë§ˆí¬ëŠ” í•œêµ­ì–´ ëª¨ë¸ ì„±ëŠ¥ì˜ í‘œì¤€"
      ],
      "metadata": {
        "id": "XUNj37MpB12F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 1. í•œêµ­ì–´ ì„±ëŠ¥ì´ ê²€ì¦ëœ KLUE ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
        "# classifier = pipeline(\"zero-shot-classification\",\n",
        "#                       model=\"klue/roberta-large\")\n",
        "classifier = pipeline(\"zero-shot-classification\",\n",
        "                      model=\"klue/roberta-large\")\n",
        "\n",
        "sequence = \"ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° ì„ì› ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.\"\n",
        "labels = ['ê²½ì œ', 'ì •ì¹˜', 'IT', 'ìŠ¤í¬ì¸ ', 'ì—°ì˜ˆ']\n",
        "\n",
        "# 2. ëª¨ë¸ì´ ì¶”ë¡ í•  ê°€ì„¤ì˜ í˜•íƒœë¥¼ í•œêµ­ì–´ë¡œ ëª…í™•íˆ ì§€ì •í•©ë‹ˆë‹¤.\n",
        "hypothesis_template = \"ì´ê²ƒì€ {} ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ì´ë‹¤.\"   # ì´ ë‚´ìš©ì€ {}ê³¼/ì™€ ê´€ë ¨ì´ ìˆë‹¤.\n",
        "\n",
        "# ë¶„ë¥˜ ì‹¤í–‰ ì‹œ í…œí”Œë¦¿ì„ í•¨ê»˜ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
        "result = classifier(sequence, labels, hypothesis_template=hypothesis_template)\n",
        "\n",
        "print('\\nâœ… KLUE ëª¨ë¸ê³¼ í•œêµ­ì–´ í…œí”Œë¦¿ ì ìš© í›„ ê²°ê³¼')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "YBE30a04B0nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nkobzHPyewgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ì¶”ê°€ ì •ë³´] ëª¨ë¸ê³¼ í…œí”Œë¦¿ ì¶”ì²œ ì˜ˆ"
      ],
      "metadata": {
        "id": "05pJ1ow0GgWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# ë°©ë²• 1: í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ë“¤ ì‹œë„\n",
        "print(\"=== ë°©ë²• 1: ë‹¤ì–‘í•œ í•œêµ­ì–´ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ===\")\n",
        "\n",
        "models_to_try = [\n",
        "    \"klue/roberta-large\",\n",
        "    \"beomi/KcELECTRA-base\",\n",
        "    \"monologg/kobert\",\n",
        "    \"xlm-roberta-large\"  # ë‹¤êµ­ì–´ ëª¨ë¸\n",
        "]\n",
        "\n",
        "sequence = \"ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° ì„ì› ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.\"\n",
        "labels = ['ê²½ì œ', 'ì •ì¹˜', 'IT', 'ìŠ¤í¬ì¸ ', 'ì—°ì˜ˆ']\n",
        "\n",
        "# ë” ëª…í™•í•œ í•œêµ­ì–´ í…œí”Œë¦¿ë“¤ ì‹œë„\n",
        "templates_to_try = [\n",
        "    \"ì´ ê¸€ì˜ ì£¼ì œëŠ” {}ì— ê´€í•œ ë‚´ìš©ì´ë‹¤.\",\n",
        "    \"ì´ ë¬¸ì¥ì€ {} ë¶„ì•¼ì— ê´€ë ¨ëœë‹¤.\",\n",
        "    \"ì´ê²ƒì€ {} ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ì´ë‹¤.\",\n",
        "    \"ì´ ë‚´ìš©ì€ {}ê³¼/ì™€ ê´€ë ¨ì´ ìˆë‹¤.\"\n",
        "]\n",
        "\n",
        "for model_name in models_to_try:\n",
        "    try:\n",
        "        print(f\"\\nğŸ“Š ëª¨ë¸: {model_name}\")\n",
        "        classifier = pipeline(\"zero-shot-classification\", model=model_name)\n",
        "\n",
        "        for i, template in enumerate(templates_to_try):\n",
        "            try:\n",
        "                result = classifier(sequence, labels, hypothesis_template=template)\n",
        "                print(f\"í…œí”Œë¦¿ {i+1}: {template}\")\n",
        "                print(f\"1ìœ„: {result['labels'][0]} ({result['scores'][0]:.4f})\")\n",
        "                print(f\"2ìœ„: {result['labels'][1]} ({result['scores'][1]:.4f})\")\n",
        "\n",
        "                if result['labels'][0] == 'ê²½ì œ':\n",
        "                    print(\"âœ… ê²½ì œê°€ 1ìœ„!\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"í…œí”Œë¦¿ {i+1} ì˜¤ë¥˜: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ëª¨ë¸ {model_name} ë¡œë“œ ì˜¤ë¥˜: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "id": "oUp5cPIgFDFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ì¶”ê°€ ì •ë³´] ì •ë³´ ì¶”ê°€í•´ì„œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ì‹œìŠ¤í…œ êµ¬ì¶•"
      ],
      "metadata": {
        "id": "JKx74EkxKULc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ë°©ë²• : í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ì‹œìŠ¤í…œ (ê°€ì¥ ì‹¤ìš©ì )\n",
        "# =============================================================================\n",
        "\n",
        "class KoreanTextClassifier:\n",
        "    def __init__(self):\n",
        "        # ê° ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì‚¬ì „ ì •ì˜\n",
        "        self.category_keywords = {\n",
        "            'ê²½ì œ': [\n",
        "                # ê¸°ì—… ê´€ë ¨\n",
        "                'ì£¼ì£¼ì´íšŒ', 'CEO', 'ì„ ì„', 'ì„ëª…', 'ì‚¬ì¥', 'íšŒì¥', 'ê²½ì˜ì§„', 'ì´ì‚¬íšŒ',\n",
        "                'ê¸°ì—…', 'íšŒì‚¬', 'ë²•ì¸', 'ê³„ì—´ì‚¬', 'ìíšŒì‚¬', 'ëª¨íšŒì‚¬',\n",
        "                # ê¸ˆìœµ ê´€ë ¨\n",
        "                'íˆ¬ì', 'ìê¸ˆ', 'ì˜ˆì‚°', 'ë§¤ì¶œ', 'ì˜ì—…ì´ìµ', 'ìˆœì´ìµ', 'ì†ì‹¤', 'ì ì', 'í‘ì',\n",
        "                'ì£¼ê°€', 'ì£¼ì‹', 'ìƒì¥', 'IPO', 'ì¦ê¶Œ', 'ê±°ë˜ì†Œ', 'ì½”ìŠ¤í”¼', 'ì½”ìŠ¤ë‹¥',\n",
        "                'ì€í–‰', 'ê¸ˆìœµ', 'ëŒ€ì¶œ', 'ì´ì', 'í™˜ìœ¨', 'ì›í™”', 'ë‹¬ëŸ¬',\n",
        "                # ì‚¬ì—… ê´€ë ¨\n",
        "                'ì‚¬ì—…', 'ì—…ê³„', 'ì‹œì¥', 'ì‚°ì—…', 'ì œì¡°', 'ìƒì‚°', 'ê³µê¸‰', 'íŒë§¤', 'ìœ í†µ',\n",
        "                'ê³„ì•½', 'í˜‘ì•½', 'MOU', 'ì¸ìˆ˜í•©ë³‘', 'M&A'\n",
        "            ],\n",
        "            'ì •ì¹˜': [\n",
        "                'ì •ë¶€', 'êµ­íšŒ', 'ëŒ€í†µë ¹', 'ì´ë¦¬', 'ì¥ê´€', 'ì •ì±…', 'ë²•ì•ˆ', 'ê°œì •ì•ˆ',\n",
        "                'ì„ ê±°', 'íˆ¬í‘œ', 'í›„ë³´', 'ì •ë‹¹', 'ì˜ì›', 'êµ­ì •ê°ì‚¬', 'ì •ì¹˜',\n",
        "                'í–‰ì •ë¶€', 'ì…ë²•ë¶€', 'ì‚¬ë²•ë¶€', 'ì§€ë°©ìì¹˜', 'ì‹œì¥', 'ë„ì§€ì‚¬'\n",
        "            ],\n",
        "            'IT': [\n",
        "                'ì†Œí”„íŠ¸ì›¨ì–´', 'í•˜ë“œì›¨ì–´', 'í”„ë¡œê·¸ë¨', 'ì•±', 'ì–´í”Œë¦¬ì¼€ì´ì…˜',\n",
        "                'ì¸ê³µì§€ëŠ¥', 'AI', 'ë¨¸ì‹ ëŸ¬ë‹', 'ë”¥ëŸ¬ë‹', 'ë¹…ë°ì´í„°', 'ë°ì´í„°',\n",
        "                'ì»´í“¨í„°', 'ì„œë²„', 'í´ë¼ìš°ë“œ', 'ë„¤íŠ¸ì›Œí¬', 'ì¸í„°ë„·', 'ì›¹',\n",
        "                'ìŠ¤ë§ˆíŠ¸í°', 'íƒœë¸”ë¦¿', 'ê¸°ìˆ ', 'ê°œë°œ', 'í”„ë¡œê·¸ë˜ë°', 'ì½”ë”©'\n",
        "            ],\n",
        "            'ìŠ¤í¬ì¸ ': [\n",
        "                'ê²½ê¸°', 'ì‹œí•©', 'ê²½ìŸ', 'ì„ ìˆ˜', 'íŒ€', 'í´ëŸ½', 'ê°ë…', 'ì½”ì¹˜',\n",
        "                'ë“ì ', 'ê³¨', 'ìŠ¹ë¦¬', 'íŒ¨ë°°', 'ìš°ìŠ¹', 'ì¤€ìš°ìŠ¹', 'ë¦¬ê·¸', 'í† ë„ˆë¨¼íŠ¸',\n",
        "                'ì˜¬ë¦¼í”½', 'ì›”ë“œì»µ', 'ì•„ì‹œì•ˆê²Œì„', 'í”„ë¡œì•¼êµ¬', 'ì¶•êµ¬', 'ë†êµ¬', 'ë°°êµ¬'\n",
        "            ],\n",
        "            'ì—°ì˜ˆ': [\n",
        "                'ë°°ìš°', 'ê°€ìˆ˜', 'ì—°ì˜ˆì¸', 'ì•„ì´ëŒ', 'ìŠ¤íƒ€', 'ì…€ëŸ¬ë¸Œë¦¬í‹°',\n",
        "                'ë“œë¼ë§ˆ', 'ì˜í™”', 'ì˜ˆëŠ¥', 'ë°©ì†¡', 'TV', 'ë¼ë””ì˜¤',\n",
        "                'ì½˜ì„œíŠ¸', 'ê³µì—°', 'ë¬´ëŒ€', 'ì•¨ë²”', 'ì‹±ê¸€', 'ë®¤ì§ë¹„ë””ì˜¤',\n",
        "                'ì—”í„°í…Œì¸ë¨¼íŠ¸', 'ê¸°íšì‚¬', 'ë°ë·”', 'ì»´ë°±'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    def classify_text(self, text, threshold=0.1):\n",
        "        \"\"\"í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì‹¤í–‰\"\"\"\n",
        "        scores = {}\n",
        "\n",
        "        # ê° ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚°\n",
        "        for category, keywords in self.category_keywords.items():\n",
        "            score = 0\n",
        "            matched_keywords = []\n",
        "\n",
        "            for keyword in keywords:\n",
        "                if keyword in text:\n",
        "                    # í‚¤ì›Œë“œ ê¸¸ì´ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ (ê¸´ í‚¤ì›Œë“œì¼ìˆ˜ë¡ ë” ì •í™•)\n",
        "                    weight = len(keyword) / 10 + 1\n",
        "                    score += weight\n",
        "                    matched_keywords.append(keyword)\n",
        "\n",
        "            scores[category] = {\n",
        "                'score': score,\n",
        "                'matched_keywords': matched_keywords\n",
        "            }\n",
        "\n",
        "        # ì ìˆ˜ ì •ê·œí™”\n",
        "        total_score = sum([s['score'] for s in scores.values()])\n",
        "\n",
        "        if total_score > 0:\n",
        "            for category in scores:\n",
        "                scores[category]['normalized_score'] = scores[category]['score'] / total_score\n",
        "        else:\n",
        "            # í‚¤ì›Œë“œ ë§¤ì¹˜ê°€ ì—†ìœ¼ë©´ ê· ë“± ë¶„ë°°\n",
        "            for category in scores:\n",
        "                scores[category]['normalized_score'] = 1 / len(scores)\n",
        "\n",
        "        # ê²°ê³¼ ì •ë ¬\n",
        "        sorted_categories = sorted(scores.items(),\n",
        "                                 key=lambda x: x[1]['normalized_score'],\n",
        "                                 reverse=True)\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'results': sorted_categories,\n",
        "            'top_category': sorted_categories[0][0],\n",
        "            'confidence': sorted_categories[0][1]['normalized_score']\n",
        "        }\n",
        "\n",
        "# ë¶„ë¥˜ê¸° ìƒì„± ë° í…ŒìŠ¤íŠ¸\n",
        "classifier = KoreanTextClassifier()\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤\n",
        "test_sentences = [\n",
        "    \"ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° CEO ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.\",\n",
        "    \"êµ­íšŒì—ì„œ ìƒˆë¡œìš´ ë²•ì•ˆì´ í†µê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.\",\n",
        "    \"ìƒˆë¡œìš´ AI ê¸°ìˆ ì´ ê°œë°œë˜ì–´ í™”ì œê°€ ë˜ê³  ìˆë‹¤.\",\n",
        "    \"í”„ë¡œì•¼êµ¬ ì‹œì¦Œì´ ì‹œì‘ë˜ì–´ íŒ¬ë“¤ì˜ ê´€ì‹¬ì´ ì§‘ì¤‘ë˜ê³  ìˆë‹¤.\",\n",
        "    \"ì¸ê¸° ë°°ìš°ê°€ ìƒˆë¡œìš´ ë“œë¼ë§ˆì— ì¶œì—°í•œë‹¤ê³  ë°œí‘œí–ˆë‹¤.\"\n",
        "]\n",
        "\n",
        "print(\"\\nâœ… í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ê²°ê³¼:\")\n",
        "for i, sentence in enumerate(test_sentences, 1):\n",
        "    result = classifier.classify_text(sentence)\n",
        "    print(f\"\\n{i}. ë¬¸ì¥: {sentence}\")\n",
        "    print(f\"   ë¶„ë¥˜: {result['top_category']} (ì‹ ë¢°ë„: {result['confidence']:.3f})\")\n",
        "\n",
        "\n",
        "    # ìƒìœ„ 3ê°œ ê²°ê³¼ì™€ ë§¤ì¹­ëœ í‚¤ì›Œë“œ ë³´ì—¬ì£¼ê¸°\n",
        "    print(\"   ìƒì„¸ ê²°ê³¼:\")\n",
        "    for rank, (category, info) in enumerate(result['results'][:3], 1):\n",
        "        keywords_str = ', '.join(info['matched_keywords'][:3])\n",
        "        if keywords_str:\n",
        "            keywords_str = f\" [í‚¤ì›Œë“œ: {keywords_str}]\"\n",
        "        print(f\"     {rank}ìœ„: {category} ({info['normalized_score']:.3f}){keywords_str}\")\n"
      ],
      "metadata": {
        "id": "F-FFcJJhJj6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0g36MizoMox8"
      }
    }
  ]
}