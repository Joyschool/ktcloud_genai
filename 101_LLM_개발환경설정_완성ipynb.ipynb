{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "collapsed_sections": [
        "5ADhlYgBTKT8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LLM ê°œë°œ í™˜ê²½ì„¤ì •"
      ],
      "metadata": {
        "id": "xAPO58qbDYi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NAmo5uhXQ46c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ğŸ’¡**ì°¸ê³  êµì¬**\n",
        "    - í•¸ì¦ˆì˜¨LLM https://www.hanbit.co.kr/store/books/look.php?p_code=B2599445240\n",
        "- ğŸ’¡ **NOTE**\n",
        "    - ì´ ë…¸íŠ¸ë¶ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì½”ë©ì—ì„œëŠ” **ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > í•˜ë“œì›¨ì–´ ê°€ì†ê¸° > T4 GPU**ë¥¼ ì„ íƒí•˜ì„¸ìš”."
      ],
      "metadata": {
        "id": "KHIcfXn8RArA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "K-OX9xcYMp_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#íŒŒì´ì¬ ë²„ì „ í™•ì¸"
      ],
      "metadata": {
        "id": "vjJh4IMODeSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Colab"
      ],
      "metadata": {
        "id": "jQHx8oG7Div4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1ERcAduBZ1q"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- (Local) win/mac"
      ],
      "metadata": {
        "id": "QY5G4ozHDlhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "py --version"
      ],
      "metadata": {
        "id": "EQydgo7UBgT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "py --list   # ì„¤ì¹˜ëœ ëª¨ë“  íŒŒì´ì¬ ë²„ì „ í™•ì¸"
      ],
      "metadata": {
        "id": "SFT0IbQzD8HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "py -3.12    # íŠ¹ì • ë²„ì „ ì‹¤í–‰ : Python 3.12 ì‹¤í–‰"
      ],
      "metadata": {
        "id": "sT7pbhyvEERL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "if sys.version_info < (3, 9):\n",
        "    print(\"Python 3.9 ë¯¸ë§Œ ë²„ì „ì´ë„¤ìš”. ì—…ê·¸ë ˆì´ë“œ í•„ìš”!\")\n",
        "else:\n",
        "    print(\"ìµœì‹  ë²„ì „ì´ë„¤ìš”!\")\n"
      ],
      "metadata": {
        "id": "YXkIjui2ThB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "print(f\"í˜„ì¬ íŒŒì´ì¬ ë²„ì „ì€ ğŸš€ {platform.python_version()} ğŸš€ ì…ë‹ˆë‹¤\")\n"
      ],
      "metadata": {
        "id": "TqkF-qErTcPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8h129nZci8Fo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ëŒ€í‘œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n"
      ],
      "metadata": {
        "id": "DG1KXzUrMqdD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **transformers**\n",
        "\n",
        "\n",
        "- **Hugging Faceê°€ ê°œë°œí•œ ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬(Transformer ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬)**\n",
        "- ìì—°ì–´ ì²˜ë¦¬, ì»´í“¨í„° ë¹„ì „, ìŒì„± ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ìµœì‹  Transformer ê¸°ë°˜ ì‚¬ì „ í•™ìŠµëœ(pretrained) ëª¨ë¸ì„ ì‰½ê³  ë¹ ë¥´ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•¨\n",
        "- 3ê°œì˜ ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì› :  PyTorch, TensorFlow, Jax\n",
        "- ìƒì„¸ì„¤ëª… : https://pypi.org/project/transformers/\n"
      ],
      "metadata": {
        "id": "cCx9g4beNOpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **ì§€ì› í”Œë«í¼ / ìš”êµ¬ì‚¬í•­**\n",
        "    - Python 3.9 ì´ìƒ, PyTorch 2.1+, TensorFlow 2.6+, Flax 0.4.1+\n",
        "- **ìš©ë„ / íŠ¹ì§•**\n",
        "    - í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ë“¤ì²˜ëŸ¼ ë‹¤ì–‘í•œ ì˜ì—­ì˜ pretrained ëª¨ë¸ì„ ê°„ë‹¨í•œ API(pipeline)ë¡œ ë¹ ë¥´ê²Œ ì‚¬ìš© ê°€ëŠ¥\n",
        "- **ì¶”ì²œ ì‚¬ìš© ì¼€ì´ìŠ¤**\n",
        "    - ë¹ ë¥´ê³  ì‰½ê²Œ NLP, ì»´í“¨í„° ë¹„ì „, ìŒì„± ë“±ì˜ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê±°ë‚˜ fine-tuning í•˜ê³ ì í•  ë•Œ"
      ],
      "metadata": {
        "id": "2SIij8mNSmaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **ì„¤ì¹˜ ë°©ë²•**"
      ],
      "metadata": {
        "id": "_9dDQ0-2SDH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì„¤ì¹˜ëœ transformers ë²„ì „ í™•ì¸  -->(ex: Version: 4.55.4)\n",
        "!pip show transformers | grep Version"
      ],
      "metadata": {
        "id": "YUQOtVxdYnhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gioKeW2nK2zX"
      },
      "outputs": [],
      "source": [
        "# Phi-3 ëª¨ë¸ê³¼ í˜¸í™˜ì„± ë•Œë¬¸ì— transformers 4.48.3 ë²„ì „ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "!pip install transformers==4.48.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì„¤ì¹˜ëœ PyTorch ë²„ì „ í™•ì¸  -->(ex: Version: 2.8.0+cu126 (+cu126-->CUDA 12.6 ë²„ì „ ì§€ì›))\n",
        "!pip show torch | grep Version\n",
        "\n",
        "# pip install torch==2.8.0"
      ],
      "metadata": {
        "id": "iBbbJcLvujq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **QuickTour**"
      ],
      "metadata": {
        "id": "lNBhIvnzPGYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ê°ì •ë¶„ì„**"
      ],
      "metadata": {
        "id": "I-yv_vjYTEn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê°ì • ë¶„ì„ íŒŒì´í”„ë¼ì¸\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "print(classifier('We are very happy to introduce pipeline to the transformers repository.'))"
      ],
      "metadata": {
        "id": "kbODkmM0PL28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlp = pipeline(\"sentiment-analysis\")\n",
        "print(nlp(\"ì´ ê°•ì˜ëŠ” ì •ë§ ì¬ë¯¸ìˆì–´ìš”!\"))\n"
      ],
      "metadata": {
        "id": "2Dqi289eTARx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ì´ë¯¸ì§€ ê°ì²´ ê°ì§€**"
      ],
      "metadata": {
        "id": "5ADhlYgBTKT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image, ImageDraw\n",
        "from transformers import pipeline\n",
        "\n",
        "# ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
        "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"\n",
        "image_data = requests.get(url, stream=True).raw\n",
        "image = Image.open(image_data)\n",
        "\n",
        "# ê°ì²´ ê°ì§€ íŒŒì´í”„ë¼ì¸\n",
        "object_detector = pipeline(\"object-detection\")\n",
        "results = object_detector(image)\n",
        "\n",
        "# ì›ë³¸ ì´ë¯¸ì§€ì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
        "draw = ImageDraw.Draw(image)\n",
        "\n",
        "for result in results:\n",
        "    box = result[\"box\"]\n",
        "    label = result[\"label\"]\n",
        "    score = result[\"score\"]\n",
        "\n",
        "    # ë°•ìŠ¤ ì¢Œí‘œ\n",
        "    x1, y1, x2, y2 = box[\"xmin\"], box[\"ymin\"], box[\"xmax\"], box[\"ymax\"]\n",
        "\n",
        "    # ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
        "    draw.rectangle(((x1, y1), (x2, y2)), outline=\"red\", width=3)\n",
        "    # ë ˆì´ë¸” + ì ìˆ˜ í‘œì‹œ\n",
        "    draw.text((x1, y1 - 10), f\"{label} {score:.2f}\", fill=\"yellow\")\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥ (Colab í™˜ê²½ì—ì„œ ì‹œê°í™”)\n",
        "image.show()   # ë¡œì»¬ í™˜ê²½ì´ë©´ ìƒˆ ì°½\n",
        "display(image) # Colab/Jupyter í™˜ê²½ì´ë©´ ë…¸íŠ¸ë¶ ì•ˆì— í‘œì‹œ\n"
      ],
      "metadata": {
        "id": "8GYQrUE5pBmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ê¸°ê³„ ë²ˆì—­**\n",
        "- ğŸ’¡ì£¼ì˜: ëª¨ë¸ ë‹¤ìš´ë¡œë“œì‹œ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆë‹¤."
      ],
      "metadata": {
        "id": "BEJAb5wotaKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Access Token ì—†ì´ ê³µê°œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n"
      ],
      "metadata": {
        "id": "0D3tsNJNulQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì¸ì¦ì´ í•„ìš”í•˜ì§€ ì•Šì€ ëŒ€ì²´ ëª¨ë¸ë“¤\n",
        "from transformers import pipeline\n",
        "\n",
        "# ì˜µì…˜ 1: Facebookì˜ NLLB ëª¨ë¸ (ì¶”ì²œ)\n",
        "translator = pipeline(\n",
        "    'translation',\n",
        "    model='facebook/nllb-200-distilled-600M',\n",
        "    src_lang='eng_Latn',\n",
        "    tgt_lang='kor_Hang',\n",
        "    max_length=512\n",
        ")\n",
        "\n",
        "text = \"Hello, how are you today?\"\n",
        "result = translator(text)\n",
        "print(f\"ì›ë¬¸: {text}\")\n",
        "print(f\"ë²ˆì—­: {result[0]['translation_text']}\")"
      ],
      "metadata": {
        "id": "5-h39UC3uZXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import builtins\n",
        "input = builtins.input  # input í•¨ìˆ˜ë¥¼ ì›ë˜ëŒ€ë¡œ ë³µêµ¬\n",
        "\n",
        "while True:\n",
        "    text = input('í•œê¸€ë¡œ ë²ˆì—­í•  ë¬¸ì¥ ì…ë ¥(\"q\"): ')\n",
        "    if (text == 'q') :\n",
        "        break\n",
        "    result = translator(text)\n",
        "    print(f\"ì›ë¬¸: {text}\")\n",
        "    print(f\"ë²ˆì—­: {result[0]['translation_text']}\")\n",
        "    print( )\n",
        "print('ë²ˆì—­ ì¢…ë£Œ!')"
      ],
      "metadata": {
        "id": "a1JcGyQgwTM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Access Token ë„£ê³  ë¹„ê³µê°œ ëª¨ë¸ ì ‘ê·¼"
      ],
      "metadata": {
        "id": "Wf2cYI1kurU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1ë‹¨ê³„: Hugging Face í† í° ìƒì„± ë° ì„¤ì •\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "# Google Colabì—ì„œ í† í° ì…ë ¥ (í•œ ë²ˆë§Œ ì‹¤í–‰)\n",
        "# https://huggingface.co/settings/tokens ì—ì„œ í† í° ìƒì„± í›„ ì…ë ¥\n",
        "login()\n",
        "\n",
        "# ë˜ëŠ” ì§ì ‘ í† í° ì…ë ¥ (ë³´ì•ˆìƒ ê¶Œì¥í•˜ì§€ ì•ŠìŒ)\n",
        "#os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = \"\""
      ],
      "metadata": {
        "id": "BzQU4DQWusb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "print(\"=== Helsinki-NLP ì˜í•œ ë²ˆì—­ ëª¨ë¸ ë¡œë”© ===\")\n",
        "\n",
        "# ì˜¬ë°”ë¥¸ ì˜ì–´â†’í•œêµ­ì–´ ë²ˆì—­ ëª¨ë¸\n",
        "translator = pipeline('translation', model='Helsinki-NLP/opus-mt-tc-big-en-ko')\n",
        "\n",
        "print(\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
        "\n",
        "# ë²ˆì—­ ì‹¤í–‰\n",
        "text = \"Hello, how are you today?\"\n",
        "result = translator(text)\n",
        "print(f\"ì›ë¬¸: {text}\")\n",
        "print(f\"ë²ˆì—­: {result[0]['translation_text']}\")"
      ],
      "metadata": {
        "id": "YzjQSo2lteru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ğŸ’¡[ì£¼ì˜] ì‹¤í–‰ì†ë„ ëŠë¦¼(ì „ì²´ ì‹¤í–‰ 5ë¶„ì •ë„ ê±¸ë¦¼)"
      ],
      "metadata": {
        "id": "3tWuei7G8Wn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import time\n",
        "import re\n",
        "\n",
        "class HighQualityTranslator:\n",
        "    \"\"\"ê³ í’ˆì§ˆ ì–‘ë°©í–¥ ë²ˆì—­ê¸°\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.translator = None\n",
        "        self.model_info = {}\n",
        "        self.translation_count = 0\n",
        "        self._initialize_best_model()\n",
        "\n",
        "    def _initialize_best_model(self):\n",
        "        \"\"\"ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì´ˆê¸°í™”\"\"\"\n",
        "\n",
        "        print(\"ğŸš€ ê³ í’ˆì§ˆ ë²ˆì—­ê¸° ì´ˆê¸°í™” ì¤‘...\")\n",
        "\n",
        "        # ì‹¤ì œ ì‘ë™í•˜ëŠ” ê³ í’ˆì§ˆ ëª¨ë¸ë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)\n",
        "        quality_models = [\n",
        "            {\n",
        "                'name': 'facebook/m2m100_1.2B',\n",
        "                'description': 'Facebook M2M100 ëŒ€í˜• ëª¨ë¸ (ìµœê³  í’ˆì§ˆ)',\n",
        "                'size': '1.2GB',\n",
        "                'type': 'm2m100_large'\n",
        "            },\n",
        "            {\n",
        "                'name': 'facebook/m2m100_418M',\n",
        "                'description': 'Facebook M2M100 ì¤‘í˜• ëª¨ë¸ (ê· í˜•)',\n",
        "                'size': '418MB',\n",
        "                'type': 'm2m100'\n",
        "            },\n",
        "            {\n",
        "                'name': 'facebook/nllb-200-distilled-600M',\n",
        "                'description': 'Facebook NLLB-200 ì¶•ì•½ ëª¨ë¸',\n",
        "                'size': '600MB',\n",
        "                'type': 'nllb'\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        for model_config in quality_models:\n",
        "            try:\n",
        "                print(f\"ğŸ”„ ì‹œë„: {model_config['description']}\")\n",
        "\n",
        "                start_time = time.time()\n",
        "\n",
        "                if 'm2m100' in model_config['type']:\n",
        "                    # M2M100 ëª¨ë¸ (ê°€ì¥ ì•ˆì •ì )\n",
        "                    self.translator = pipeline(\n",
        "                        'translation',\n",
        "                        model=model_config['name'],\n",
        "                        device=-1,\n",
        "                        torch_dtype='auto'\n",
        "                    )\n",
        "                    self.src_lang_en = 'en'\n",
        "                    self.tgt_lang_ko = 'ko'\n",
        "                    self.src_lang_ko = 'ko'\n",
        "                    self.tgt_lang_en = 'en'\n",
        "\n",
        "                elif model_config['type'] == 'nllb':\n",
        "                    # NLLB ëª¨ë¸\n",
        "                    self.translator = pipeline(\n",
        "                        'translation',\n",
        "                        model=model_config['name'],\n",
        "                        device=-1\n",
        "                    )\n",
        "                    self.src_lang_en = 'eng_Latn'\n",
        "                    self.tgt_lang_ko = 'kor_Hang'\n",
        "                    self.src_lang_ko = 'kor_Hang'\n",
        "                    self.tgt_lang_en = 'eng_Latn'\n",
        "\n",
        "                load_time = time.time() - start_time\n",
        "\n",
        "                # í…ŒìŠ¤íŠ¸ ë²ˆì—­ìœ¼ë¡œ í’ˆì§ˆ í™•ì¸\n",
        "                test_en = \"Hello, how are you?\"\n",
        "                test_ko = \"ì•ˆë…•í•˜ì„¸ìš”, ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?\"\n",
        "\n",
        "                # ì˜â†’í•œ í…ŒìŠ¤íŠ¸\n",
        "                en_result = self._translate_with_params(test_en, self.src_lang_en, self.tgt_lang_ko)\n",
        "                # í•œâ†’ì˜ í…ŒìŠ¤íŠ¸\n",
        "                ko_result = self._translate_with_params(test_ko, self.src_lang_ko, self.tgt_lang_en)\n",
        "\n",
        "                print(f\"âœ… ì„±ê³µ! ë¡œë”© ì‹œê°„: {load_time:.2f}ì´ˆ\")\n",
        "                print(f\"ğŸ“Š ì˜â†’í•œ í…ŒìŠ¤íŠ¸: '{test_en}' â†’ '{en_result}'\")\n",
        "                print(f\"ğŸ“Š í•œâ†’ì˜ í…ŒìŠ¤íŠ¸: '{test_ko}' â†’ '{ko_result}'\")\n",
        "\n",
        "                self.model_info = {\n",
        "                    'name': model_config['name'],\n",
        "                    'description': model_config['description'],\n",
        "                    'size': model_config['size'],\n",
        "                    'type': model_config['type'],\n",
        "                    'load_time': f\"{load_time:.2f}ì´ˆ\"\n",
        "                }\n",
        "\n",
        "                break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ ì‹¤íŒ¨: {str(e)[:60]}...\")\n",
        "                continue\n",
        "\n",
        "        if self.translator is None:\n",
        "            raise RuntimeError(\"ì‚¬ìš© ê°€ëŠ¥í•œ ê³ í’ˆì§ˆ ë²ˆì—­ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    def _translate_with_params(self, text, src_lang, tgt_lang):\n",
        "        \"\"\"íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•œ ë²ˆì—­ ì‹¤í–‰\"\"\"\n",
        "        try:\n",
        "            if 'm2m100' in self.model_info['type']:\n",
        "                # M2M100 ëª¨ë¸ìš©\n",
        "                result = self.translator(text, src_lang=src_lang, tgt_lang=tgt_lang, max_length=128)\n",
        "            else:\n",
        "                # NLLB ëª¨ë¸ìš©\n",
        "                result = self.translator(text, src_lang=src_lang, tgt_lang=tgt_lang, max_length=128)\n",
        "\n",
        "            return result[0]['translation_text']\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"ë²ˆì—­ ì˜¤ë¥˜: {str(e)[:50]}...\"\n",
        "\n",
        "    def detect_language(self, text):\n",
        "        \"\"\"ê°œì„ ëœ ì–¸ì–´ ê°ì§€\"\"\"\n",
        "        # í•œê¸€ ë¬¸ì ë¹„ìœ¨ ê³„ì‚°\n",
        "        korean_chars = len(re.findall(r'[ê°€-í£]', text))\n",
        "        total_chars = len(re.sub(r'\\s+', '', text))  # ê³µë°± ì œì™¸\n",
        "\n",
        "        if total_chars == 0:\n",
        "            return 'unknown'\n",
        "\n",
        "        korean_ratio = korean_chars / total_chars\n",
        "\n",
        "        # í•œê¸€ì´ 30% ì´ìƒì´ë©´ í•œêµ­ì–´ë¡œ íŒë‹¨\n",
        "        if korean_ratio >= 0.3:\n",
        "            return 'ko'\n",
        "        # ì˜ë¬¸ìë‚˜ ìˆ«ìê°€ ì£¼ë¥¼ ì´ë£¨ë©´ ì˜ì–´ë¡œ íŒë‹¨\n",
        "        elif re.search(r'[a-zA-Z]', text):\n",
        "            return 'en'\n",
        "        else:\n",
        "            return 'unknown'\n",
        "\n",
        "    def translate_en_to_ko(self, english_text):\n",
        "        \"\"\"ì˜ì–´â†’í•œêµ­ì–´ ë²ˆì—­\"\"\"\n",
        "        if not english_text.strip():\n",
        "            return \"ë²ˆì—­í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        try:\n",
        "            result = self._translate_with_params(\n",
        "                english_text.strip(),\n",
        "                self.src_lang_en,\n",
        "                self.tgt_lang_ko\n",
        "            )\n",
        "            self.translation_count += 1\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"ì˜â†’í•œ ë²ˆì—­ ì‹¤íŒ¨: {str(e)}\"\n",
        "\n",
        "    def translate_ko_to_en(self, korean_text):\n",
        "        \"\"\"í•œêµ­ì–´â†’ì˜ì–´ ë²ˆì—­\"\"\"\n",
        "        if not korean_text.strip():\n",
        "            return \"ë²ˆì—­í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        try:\n",
        "            result = self._translate_with_params(\n",
        "                korean_text.strip(),\n",
        "                self.src_lang_ko,\n",
        "                self.tgt_lang_en\n",
        "            )\n",
        "            self.translation_count += 1\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"í•œâ†’ì˜ ë²ˆì—­ ì‹¤íŒ¨: {str(e)}\"\n",
        "\n",
        "    def auto_translate(self, text):\n",
        "        \"\"\"ìë™ ì–¸ì–´ ê°ì§€ ë° ë²ˆì—­\"\"\"\n",
        "        if not text.strip():\n",
        "            return \"ë²ˆì—­í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        detected_lang = self.detect_language(text)\n",
        "\n",
        "        if detected_lang == 'ko':\n",
        "            translation = self.translate_ko_to_en(text)\n",
        "            return f\"ğŸ‡°ğŸ‡·â†’ğŸ‡ºğŸ‡¸ {translation}\"\n",
        "        elif detected_lang == 'en':\n",
        "            translation = self.translate_en_to_ko(text)\n",
        "            return f\"ğŸ‡ºğŸ‡¸â†’ğŸ‡°ğŸ‡· {translation}\"\n",
        "        else:\n",
        "            # ì¼ë‹¨ ì˜ì–´ë¡œ ê°€ì •í•˜ê³  ë²ˆì—­ ì‹œë„\n",
        "            translation = self.translate_en_to_ko(text)\n",
        "            return f\"ğŸ”¤â†’ğŸ‡°ğŸ‡· {translation}\"\n",
        "\n",
        "    def get_model_info(self):\n",
        "        \"\"\"ëª¨ë¸ ì •ë³´ ë°˜í™˜\"\"\"\n",
        "        info = self.model_info.copy()\n",
        "        info['total_translations'] = self.translation_count\n",
        "        return info\n",
        "\n",
        "    def batch_translate(self, texts, direction='auto'):\n",
        "        \"\"\"ë°°ì¹˜ ë²ˆì—­\"\"\"\n",
        "        results = []\n",
        "\n",
        "        print(f\"ğŸ“¦ ë°°ì¹˜ ë²ˆì—­ ì‹œì‘ ({len(texts)}ê°œ ë¬¸ì¥)\")\n",
        "\n",
        "        for i, text in enumerate(texts, 1):\n",
        "            if direction == 'en_to_ko':\n",
        "                result = self.translate_en_to_ko(text)\n",
        "            elif direction == 'ko_to_en':\n",
        "                result = self.translate_ko_to_en(text)\n",
        "            else:\n",
        "                result = self.auto_translate(text)\n",
        "\n",
        "            results.append(result)\n",
        "            print(f\"ì§„í–‰ë¥ : {i}/{len(texts)} ({i/len(texts)*100:.1f}%)\")\n",
        "\n",
        "        return results\n",
        "\n",
        "# ì‹¤ì œ ì‚¬ìš© ë° í…ŒìŠ¤íŠ¸\n",
        "print(\"=== ê³ í’ˆì§ˆ ì–‘ë°©í–¥ ë²ˆì—­ê¸° í…ŒìŠ¤íŠ¸ ===\")\n",
        "\n",
        "try:\n",
        "    # ë²ˆì—­ê¸° ì´ˆê¸°í™”\n",
        "    translator = HighQualityTranslator()\n",
        "\n",
        "    # ëª¨ë¸ ì •ë³´ ì¶œë ¥\n",
        "    info = translator.get_model_info()\n",
        "    print(f\"\\nğŸ“‹ ë¡œë”©ëœ ëª¨ë¸ ì •ë³´:\")\n",
        "    for key, value in info.items():\n",
        "        print(f\"   {key}: {value}\")\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # 1. ì˜ì–´â†’í•œêµ­ì–´ ë²ˆì—­ í…ŒìŠ¤íŠ¸\n",
        "    print(f\"ğŸ”¤ ì˜ì–´â†’í•œêµ­ì–´ ë²ˆì—­ í…ŒìŠ¤íŠ¸:\")\n",
        "    en_sentences = [\n",
        "        \"Good morning! How are you today?\",\n",
        "        \"I love studying artificial intelligence and machine learning.\",\n",
        "        \"The weather is beautiful, perfect for a walk in the park.\",\n",
        "        \"Thank you so much for your help with this project.\",\n",
        "        \"Python is an excellent programming language for beginners.\"\n",
        "    ]\n",
        "\n",
        "    for i, sentence in enumerate(en_sentences, 1):\n",
        "        translation = translator.translate_en_to_ko(sentence)\n",
        "        print(f\"\\n{i}. EN: {sentence}\")\n",
        "        print(f\"   KO: {translation}\")\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # 2. í•œêµ­ì–´â†’ì˜ì–´ ë²ˆì—­ í…ŒìŠ¤íŠ¸\n",
        "    print(f\"ğŸ”¤ í•œêµ­ì–´â†’ì˜ì–´ ë²ˆì—­ í…ŒìŠ¤íŠ¸:\")\n",
        "    ko_sentences = [\n",
        "        \"ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?\",\n",
        "        \"ì €ëŠ” ì¸ê³µì§€ëŠ¥ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì„ ê³µë¶€í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•©ë‹ˆë‹¤.\",\n",
        "        \"ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”, ê³µì›ì„ ì‚°ì±…í•˜ê¸° ì™„ë²½í•´ìš”.\",\n",
        "        \"ì´ í”„ë¡œì íŠ¸ë¥¼ ë„ì™€ì£¼ì…”ì„œ ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤.\",\n",
        "        \"íŒŒì´ì¬ì€ ì´ˆë³´ìë“¤ì—ê²Œ í›Œë¥­í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\"\n",
        "    ]\n",
        "\n",
        "    for i, sentence in enumerate(ko_sentences, 1):\n",
        "        translation = translator.translate_ko_to_en(sentence)\n",
        "        print(f\"\\n{i}. KO: {sentence}\")\n",
        "        print(f\"   EN: {translation}\")\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # 3. ìë™ ì–¸ì–´ ê°ì§€ ë²ˆì—­ í…ŒìŠ¤íŠ¸\n",
        "    print(f\"ğŸ¤– ìë™ ì–¸ì–´ ê°ì§€ ë²ˆì—­ í…ŒìŠ¤íŠ¸:\")\n",
        "    mixed_sentences = [\n",
        "        \"Hello world!\",\n",
        "        \"ì•ˆë…• ì„¸ìƒ!\",\n",
        "        \"I'm learning Korean language.\",\n",
        "        \"í•œêµ­ì–´ë¥¼ ë°°ìš°ê³  ìˆì–´ìš”.\",\n",
        "        \"Artificial Intelligence is amazing!\",\n",
        "        \"ì¸ê³µì§€ëŠ¥ì€ ì •ë§ ë†€ë¼ì›Œìš”!\"\n",
        "    ]\n",
        "\n",
        "    for i, sentence in enumerate(mixed_sentences, 1):\n",
        "        detected_lang = translator.detect_language(sentence)\n",
        "        translation = translator.auto_translate(sentence)\n",
        "        print(f\"\\n{i}. ì…ë ¥: {sentence}\")\n",
        "        print(f\"   ê°ì§€ì–¸ì–´: {detected_lang}\")\n",
        "        print(f\"   ë²ˆì—­: {translation}\")\n",
        "\n",
        "    # 4. ìµœì¢… í†µê³„\n",
        "    final_info = translator.get_model_info()\n",
        "    print(f\"\\nğŸ“Š ë²ˆì—­ í†µê³„:\")\n",
        "    print(f\"   ì´ ë²ˆì—­ íšŸìˆ˜: {final_info['total_translations']}íšŒ\")\n",
        "    print(f\"   ì‚¬ìš© ëª¨ë¸: {final_info['description']}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ë²ˆì—­ê¸° ì˜¤ë¥˜: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "6HApDSDG01zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "v7LZ-3Lr82Lf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Phiâ€‘3**\n",
        "\n",
        "- **Microsoftê°€ ê°œë°œí•œ ì†Œí˜• ì–¸ì–´ ëª¨ë¸(SLM) ì‹œë¦¬ì¦ˆ**\n",
        "    - Phiâ€‘3â€‘mini (3.8B íŒŒë¼ë¯¸í„°), Phiâ€‘3â€‘small (ì•½ 7B), Phiâ€‘3â€‘medium (14B) ë“± ë‹¤ì–‘í•œ ë³€í˜•ì„ í¬í•¨\n",
        "- íŒŒë¼ë¯¸í„° & ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°\n",
        "    - Phi-3-mini: 3.8B íŒŒë¼ë¯¸í„°, 4K ë° í™•ì¥ëœ 128K ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì§€ì›\n",
        "    - Phiâ€‘3â€‘small: ì•½ 7B, ê¸°ë³¸ 8K ì»¨í…ìŠ¤íŠ¸\n",
        "    - Phiâ€‘3â€‘medium: 14B ê¸°ëŠ¥, ë” ë„“ì€ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ ëŠ¥ë ¥\n",
        "    - **microsoft/Phi-3-mini-4k-instruct**\n",
        "\n",
        "- í•™ìŠµ ë°ì´í„° & ë¯¸ì„¸ì¡°ì •\n",
        "    - ì´ 3.3ì¡° í† í° ì´ìƒìœ¼ë¡œ êµ¬ì„±ëœ ê³ í’ˆì§ˆ í•„í„°ë§ ì›¹ ë°ì´í„°, í•©ì„± ë°ì´í„° ë“±ì„ í™œìš©. ì´í›„ **Supervised Fine-Tuning (SFT)** ê³¼ Direct Preference Optimization (DPO) ê¸°ë²•ì„ í†µí•´ ì¸ê°„ ì„ í˜¸ë„ ë° ì•ˆì „ ê¸°ì¤€ì— ë§ì¶° ë¯¸ì„¸ ì¡°ì •ë¨\n",
        "- ì„±ëŠ¥ ì§€í‘œ\n",
        "    - ìµœì†Œí˜• ëª¨ë¸(Phi-3-mini)ë„ MMLU 69%, MT-bench 8.38 ë“± ì„±ëŠ¥ìœ¼ë¡œ Mixtral 8x7B, GPT-3.5ì™€ ìœ ì‚¬í•œ ìˆ˜ì¤€\n",
        "    - Phiâ€‘3â€‘small ë° mediumëŠ” ê°ê° MMLU 75% ë° 78%, MTâ€‘bench 8.7 ë° 8.9ë¥¼ ë‹¬ì„±\n",
        "    - ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬(HellaSwag, WinoGrande, TruthfulQA, HumanEval ë“±)ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì„\n",
        "\n",
        "- ê´€ë ¨ ëª¨ë¸ë“¤\n",
        "    - Phi-3-mini-128k-instruct: 128K ì»¨í…ìŠ¤íŠ¸ ì§€ì› ë²„ì „\n",
        "    - Phi-3.5-mini-instruct: ë‹¤êµ­ì–´ ì§€ì› ê°•í™” ë²„ì „ (2024ë…„ 8ì›”)\n",
        "    - Phi-4-mini-instruct: ìµœì‹  ì•„í‚¤í…ì²˜ ì ìš© ë²„ì „\n"
      ],
      "metadata": {
        "id": "olZXCZdcWh_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "| í•­ëª© | ì„¸ë¶€ ì •ë³´ |\n",
        "|--- |--- |\n",
        "|ëª¨ë¸ í¬ê¸° |3.8ì–µ íŒŒë¼ë¯¸í„° |\n",
        "|ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ |4K í† í° |\n",
        "|í›ˆë ¨ í† í° ìˆ˜ |3.3ì¡° í† í° |\n",
        "|ì–´íœ˜ í¬ê¸° |32,064 í† í° |\n",
        "|ì•„í‚¤í…ì²˜ |Dense decoder-only Transformer |\n",
        "|ì¶œì‹œì¼ |2024ë…„ 6ì›” |\n",
        "|ë¼ì´ì„ ìŠ¤ |MIT ë¼ì´ì„ ìŠ¤ |"
      ],
      "metadata": {
        "id": "58ekeCbKGWqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "|ë²¤ì¹˜ë§ˆí¬ |Phi-3-mini ì„±ëŠ¥ |ë¹„êµ ëª¨ë¸ ì„±ëŠ¥ |\n",
        "|--- |--- |--- |\n",
        "|MMLU |69% |GPT-3.5: ~70% |\n",
        "|MT-bench |8.38 |GPT-3.5: ~8.5 |\n",
        "|HumanEval |ë†’ì€ ì„±ëŠ¥ |í™•ì‹¤í•˜ì§€ ì•ŠìŒ |\n",
        "|GSM-8K |ìš°ìˆ˜ |í™•ì‹¤í•˜ì§€ ì•ŠìŒ |"
      ],
      "metadata": {
        "id": "emkEAj1TGbNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QuickTour"
      ],
      "metadata": {
        "id": "GYYPM8LKYKtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ëª¨ë¸ ë¡œë“œ ë° í† í° ìƒì„±\n"
      ],
      "metadata": {
        "id": "iiJCX0VgX5F3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ì¤‘ê°„ìˆ˜ì¤€ API(Task-specific Models) ë°©ì‹ --> ì½”ë©(ë¬´ë£Œ)ì—ì„œ ì‹¤í–‰ ì˜¤ë˜ ê±¸ë¦¼(5ë¶„â­¡)"
      ],
      "metadata": {
        "id": "ye9p2FAuak2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phi-3-mini ë¡œë“œ ë° ê°„ë‹¨ ìƒì„± (Transformers)\n",
        "#   ì„ í˜•ì  ìƒì„± íë¦„ì„ ì²´í—˜í•˜ë©° ëª¨ë¸ ì‘ë™ ì›ë¦¬ë¥¼ ì„¤ëª…í•˜ê¸° ì¢‹ë‹¤.\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n"
      ],
      "metadata": {
        "id": "BZfCMj2BYK4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ê³ ìˆ˜ì¤€ API(pipeline) ë°©ì‹\n",
        "\n",
        "ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì§ì ‘ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ pipeline í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ í›¨ì”¬ ì‰½ìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "2c9r0tymaW76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# íŒŒì´í”„ë¼ì¸ì„ ë§Œë“­ë‹ˆë‹¤.\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=500,\n",
        "    do_sample=False\n",
        ")"
      ],
      "metadata": {
        "id": "5Foxafz3aXEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ğŸ’¡ **[ì°¸ê³ ] PyTorchì˜ ì–¸ì–´ ëª¨ë¸ ìƒì„± í•¨ìˆ˜ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì£¼ìš” ë§¤ê°œë³€ìˆ˜**\n",
        "\n",
        "| ë§¤ê°œë³€ìˆ˜ | ì˜ë¯¸ | ê¸°ë³¸ê°’ | ë²”ìœ„ | ì„¤ëª… |\n",
        "|--- |--- |--- |--- |--- |\n",
        "| **max_new_tokens**  |ëª¨ë¸ì´ ìƒì„±í•  ìƒˆë¡œìš´ í† í°ì˜ ìµœëŒ€ ê°œìˆ˜  |ëª¨ë¸ë§ˆë‹¤ ë‹¤ë¦„ (ë³´í†µ 50-100)  |1 ~ ëª¨ë¸ì˜ ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´  |  |\n",
        "|**temperature**  |ëª¨ë¸ ì¶œë ¥ì˜ ì°½ì˜ì„±ê³¼ ì¼ê´€ì„±ì„ ì¡°ì ˆí•˜ëŠ” ë§¤ê°œë³€ìˆ˜  |1.0  |0.0 ~ 2.0 (ì¼ë°˜ì ìœ¼ë¡œ 0.1 ~ 1.5)  |Softmax í•¨ìˆ˜ì˜ ì˜¨ë„ ë§¤ê°œë³€ìˆ˜  |\n",
        "|**do_sample**  |ìƒ˜í”Œë§ ë°©ì‹ ì„ íƒ (í™•ë¥ ì  vs ê²°ì •ì )  |False  |Boolean (True/False)  |  |"
      ],
      "metadata": {
        "id": "4clCIvrf_qbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------\n",
        "# max_new_tokens\n",
        "#--------------------------\n",
        "# ì§§ì€ ë‹µë³€ (ìš”ì•½, ë¶„ë¥˜)\n",
        "max_new_tokens=50\n",
        "\n",
        "# ì¤‘ê°„ ê¸¸ì´ ë‹µë³€ (ì„¤ëª…, Q&A)\n",
        "max_new_tokens=200\n",
        "\n",
        "# ê¸´ ë‹µë³€ (ì—ì„¸ì´, ë³´ê³ ì„œ)\n",
        "max_new_tokens=500"
      ],
      "metadata": {
        "id": "01YVt_XCA6MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Temperature** ê°’ì— ë”°ë¥¸ íŠ¹ì„±\n",
        "\n",
        "|Temperature|íŠ¹ì„±|ì‚¬ìš© ìƒí™©|ì˜ˆì‹œ|\n",
        "|--- |--- |--- |---|\n",
        "|0.0 | ì™„ì „íˆ ê²°ì •ì , í•­ìƒ ê°™ì€ ì¶œë ¥ | ì •í™•í•œ ë‹µë³€ í•„ìš” | ìˆ˜í•™ ë¬¸ì œ, ë²ˆì—­ |\n",
        "|0.3-0.5 | ì•ˆì •ì , ì¼ê´€ì„± ë†’ìŒ | ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ, ê¸°ìˆ  ì„¤ëª… | ë³´ê³ ì„œ ì‘ì„± |\n",
        "|0.7 | ê· í˜• ì¡íŒ ì°½ì˜ì„±ê³¼ ì¼ê´€ì„± | ì¼ë°˜ì ì¸ ëŒ€í™”, êµìœ¡ | ì±—ë´‡, Q&A |\n",
        "|1.0 | í‘œì¤€ ì°½ì˜ì„± | ê¸°ë³¸ ì„¤ì • | ê¸°ë³¸ ëŒ€í™”\n",
        "|1.5-2.0 | ë§¤ìš° ì°½ì˜ì , ì˜ˆì¸¡ ë¶ˆê°€ | ì°½ì‘ í™œë™, ë¸Œë ˆì¸ìŠ¤í† ë° | ì†Œì„¤, ì‹œ ì°½ì‘ |"
      ],
      "metadata": {
        "id": "36N_NtELBcBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------\n",
        "# Temperature ì‘ë™ ì›ë¦¬\n",
        "#--------------------------\n",
        "# ìˆ˜í•™ì  í‘œí˜„\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def apply_temperature(logits, temperature):\n",
        "    \"\"\"Temperature scaling ì ìš©\"\"\"\n",
        "    if temperature == 0:\n",
        "        return torch.argmax(logits, dim=-1)\n",
        "    else:\n",
        "        scaled_logits = logits / temperature\n",
        "        probabilities = F.softmax(scaled_logits, dim=-1)\n",
        "        return torch.multinomial(probabilities, 1)\n",
        "\n",
        "# ì˜ˆì‹œ: ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ í™•ë¥ \n",
        "original_probs = [0.6, 0.3, 0.1]  # \"ì¢‹ì€\", \"ë‚˜ìœ\", \"ë³´í†µ\"\n",
        "\n",
        "# Temperature = 0.5 (ë” í™•ì‹¤í•œ ì„ íƒ)\n",
        "temp_05_probs = [0.8, 0.15, 0.05]\n",
        "\n",
        "# Temperature = 1.5 (ë” ë‹¤ì–‘í•œ ì„ íƒ)\n",
        "temp_15_probs = [0.45, 0.35, 0.2]"
      ],
      "metadata": {
        "id": "kL8K-xSIBQUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **do_sample**ì˜µì…˜ ë¹„êµ\n",
        "\n",
        "| do_sample |  ë°©ì‹ | íŠ¹ì§• | ì–¸ì œ ì‚¬ìš©? |\n",
        "|--- |--- |--- |--- |\n",
        "| False | Greedy Decoding | í•­ìƒ ê°€ì¥ í™•ë¥  ë†’ì€ í† í° ì„ íƒ | ì •í™•ì„±ì´ ì¤‘ìš”í•œ ì‘ì—… |\n",
        "| True | Sampling | í™•ë¥ ì— ë”°ë¼ ëœë¤í•˜ê²Œ ì„ íƒ | ì°½ì˜ì„±ì´ í•„ìš”í•œ ì‘ì—… |"
      ],
      "metadata": {
        "id": "j9P_SQq__0Jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do_sample=False (Greedy)\n",
        "ë‹¤ìŒ ë‹¨ì–´ í™•ë¥ : {\"ì¢‹ì€\": 0.6, \"ë‚˜ìœ\": 0.3, \"ë³´í†µ\": 0.1}\n",
        "ì„ íƒ: í•­ìƒ \"ì¢‹ì€\" (ê°€ì¥ ë†’ì€ í™•ë¥ )\n",
        "\n",
        "# do_sample=True (Sampling)\n",
        "ë‹¤ìŒ ë‹¨ì–´ í™•ë¥ : {\"ì¢‹ì€\": 0.6, \"ë‚˜ìœ\": 0.3, \"ë³´í†µ\": 0.1}\n",
        "ì„ íƒ: 60% í™•ë¥ ë¡œ \"ì¢‹ì€\", 30% í™•ë¥ ë¡œ \"ë‚˜ìœ\", 10% í™•ë¥ ë¡œ \"ë³´í†µ\""
      ],
      "metadata": {
        "id": "TvPx7P_UCtMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NR4g4e44_0GB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ê³  ëª¨ë¸ì— ì£¼ì…"
      ],
      "metadata": {
        "id": "sxUo-N0cbC_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# í”„ë¡¬í”„íŠ¸ (ì‚¬ìš©ì ì…ë ¥ / ì¿¼ë¦¬)\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Create a funny joke about chickens.\"}\n",
        "]\n",
        "\n",
        "# ì¶œë ¥ ìƒì„±\n",
        "output = generator(messages)\n",
        "print(output[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "hJOl9GZIbDJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [ì‹¤ìŠµ] ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„±"
      ],
      "metadata": {
        "id": "hLTlimBYRfid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import torch\n",
        "\n",
        "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,  # GPU ë©”ëª¨ë¦¬ ì ˆì•½\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# ì±„íŒ… í˜•ì‹ í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"},\n",
        "    {\"role\": \"user\", \"content\": \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"}\n",
        "]\n",
        "\n",
        "# í† í°í™” ë° ìƒì„±\n",
        "input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ìƒì„±\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=200,  #ëª¨ë¸ì´ ìƒì„±í•  ìƒˆë¡œìš´ í† í°ì˜ ìµœëŒ€ ê°œìˆ˜\n",
        "        temperature=0.7,\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print('-' * 50)\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "1z-FreQiRlsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [ì‹¤ìŠµ] ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸"
      ],
      "metadata": {
        "id": "uRwt3o1zSpV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def coding_assistant_example():\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"},\n",
        "        {\"role\": \"user\", \"content\": \"í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ì„ ê³„ì‚°í•˜ëŠ” íš¨ìœ¨ì ì¸ í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\"}\n",
        "    ]\n",
        "\n",
        "    # íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=300,\n",
        "        temperature=0.3\n",
        "    )\n",
        "\n",
        "    # ì‘ë‹µ ìƒì„±\n",
        "    print('-' * 50)\n",
        "    response = pipe(messages)\n",
        "    print(response[0]['generated_text'])\n",
        "\n",
        "coding_assistant_example()"
      ],
      "metadata": {
        "id": "Bgv8CP_rSw6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [ì‹¤ìŠµ] êµìœ¡ìš© Q&A ì‹œìŠ¤í…œ"
      ],
      "metadata": {
        "id": "9qDx6AzEShCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def educational_qa_system():\n",
        "    \"\"\"êµìœ¡ìš© ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\"\"\"\n",
        "\n",
        "    class Phi3EducationBot:\n",
        "        def __init__(self, model_name=\"microsoft/Phi-3-mini-4k-instruct\"):\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "            self.pipe = pipeline(\"text-generation\",\n",
        "                               model=self.model,\n",
        "                               tokenizer=self.tokenizer)\n",
        "\n",
        "        def answer_question(self, question, subject=\"ì»´í“¨í„°ê³µí•™\"):\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": f\"ë‹¹ì‹ ì€ {subject} ì „ë¬¸ ê°•ì‚¬ì…ë‹ˆë‹¤. í•™ìƒë“¤ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"},\n",
        "                {\"role\": \"user\", \"content\": question}\n",
        "            ]\n",
        "\n",
        "            response = self.pipe(messages, max_new_tokens=250)\n",
        "            return response[0]['generated_text']\n",
        "\n",
        "    # ì‚¬ìš© ì˜ˆì‹œ\n",
        "    bot = Phi3EducationBot()\n",
        "    answer = bot.answer_question(\"ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\")\n",
        "    print(answer)\n",
        "\n",
        "educational_qa_system()"
      ],
      "metadata": {
        "id": "d7m4784iSMhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [ë¯¸ì…˜] OOO ì‹œìŠ¤í…œ ë§Œë“¤ê¸°"
      ],
      "metadata": {
        "id": "Dk2UMp3ETSyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0g36MizoMox8"
      }
    }
  ]
}